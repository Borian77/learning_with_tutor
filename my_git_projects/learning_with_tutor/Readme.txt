Описание проекта
Из «Бета-Банка» стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.
Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Вам предоставлены исторические данные о поведении клиентов и расторжении договоров с банком. 
Постройте модель с предельно большим значением F1-меры. Чтобы сдать проект успешно, нужно довести метрику до 0.59. Проверьте F1-меру на тестовой выборке самостоятельно.
Дополнительно измеряйте AUC-ROC, сравнивайте её значение с F1-мерой.

Входные данные:
- Данные находятся в файле /datasets/Churn.csv (англ. «отток клиентов»).
Признаки:
- RowNumber — индекс строки в данных
- CustomerId — уникальный идентификатор клиента
- Surname — фамилия
- CreditScore — кредитный рейтинг
- Geography — страна проживания
- Gender — пол
- Age — возраст
- Tenure — сколько лет человек является клиентом банка
- Balance — баланс на счёте
- NumOfProducts — количество продуктов банка, используемых клиентом
- HasCrCard — наличие кредитной карты
- IsActiveMember — активность клиента
- EstimatedSalary — предполагаемая зарплата
Целевой признак:
- Exited — факт ухода клиента

Что сделано:
- Загрузили данные, проверили на пропуски, где возможно было - заменили пропуски, проверили на дубликаты, проанализировали признаки, выявили те, которые не влияют на исследование и удалили их.
- Подготовили датафрейм для исследования. Был сформирован новый датафрейм.
- Сформировали выборки в следующем соотношении:
	- обучающая - 0.6, 
	- валидационная - 0.2, 
	- тестовая - 0.2.
- Масштабировали признаки всех трех выборок (Обучающей, валидационной и тестовой).
- Определили наличие дисбаланса. В исходных данных наблюдался значительный дисбаланс (около 80% ответов целевого признака были негативными и только около 20% - позитивными), из-за чего обученная на этих данных модель не проходила проверку на адекватность. Все модели с исходными данными характеризовались высокой степенью ошибок и низким качеством взвешенной величины (F1) — модели показывали низкие результаты точности и полноты.
- Построили матрицы ошибок для моделей.
- Устранили дисбаланс классов в обучающей выборки методами upsampling и downsample — увеличили количество значений позитивного класса в 4 раза, и уменьшили количество значений негативного класса в 4 раза, соответственно. Тем самым достигли лучшего результата баланса классов в обучеющей выборке: 1 - 0.509964; 0 - 0.490036.
- Разобрали несколько вариантов борьбы с дисбалансом upsampling и downsampling.

Результаты: 
На сбалансированной выборке все модели показали результат выше, чем на несбалансированной. Лучшие показатели были у модели случайного леса:
- Полнота: 0.6259946949602122
- Точность: 0.6537396121883656
- F1-мера: 0.6395663956639566
- Auc_roc: 0.8614035346070091
Финальная модель прошла проверку на адекватность в сравнении с конcтантной моделью:
- accuracy_score константой модели: 0.7926292629262927
- accuracy_score финальной модели: 0.8460692688290269
- AUC-ROC константой модели: 0.5
- AUC-ROC финальной модели: 0.7507180729251574
- F1-меру константой модели: 0.0
- F1-меру финальной модели: 0.5988538681948424